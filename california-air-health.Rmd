---
title: "Something Clever"
author: "Ruthe Huang, Xinye Li, Emily Scott"
date: "December 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, fig.align = "center")
```

## Motivation and Overview

Nearly [90 million Americans](https://i.redd.it/bbnxf9b8rm321.jpg) are breathing air that doesn't meet the World Health Oranizations safe $\text{PM}_{2.5}$ limit. The [UK Department for Environment, Food & Rural Affairs](https://laqm.defra.gov.uk/public-health/pm25.html) states that long-term $\text{PM}_{2.5}$ exposure poses a variety of health risks; most commonly, health consequences due to long-term $\text{PM}_{2.5}$ exposure take the form of cardiovascular or respiratory diseases. This poses a serious public health problem because such diseases reduce both quality and length of life. 

There are many sources of $\text{PM}_{2.5}$, including vehicular emissions and ash. California's large traffic volume and increasingly frequent wildfires both contribute to the state's $\text{PM}_{2.5}$ levels. While wildfires are natural, climate change is making them more common and more severe. According to the [Environmental Protection Agency](https://www.epa.gov/sites/production/files/2016-09/documents/climate-change-ca.pdf), the state of California is becoming warmer as a whole and southern California, in particular, is becoming drier. California's average annual precipitation and temperature from 1895-2017 are shown below. These unnaturally warm and dry conditions promote frequent and devastating wildfires. 

![](https://fivethirtyeight.com/wp-content/uploads/2018/11/science-fires-2.png?w=1150)

California's burgeoning population has expanded into many high-risk fire zones. [TIME](http://time.com/4985252/california-wildfires-fires-climate-change/) reports on a 2017 Verisk risk analysis which found that "15% -- or over 2 million -- of California's homes [are] in high or extremely high wildfire risk zones and another 12% in moderate risk areas." Concurrently, large fires have become more common in California, as seen in the chart below. Each bar represents a single fire, and the bar height represents the size of areas burned in acres. The proximity of these populations to $\text{PM}_{2.5}$ sources such as wildfires puts them at increased risk of unhealthy exposure levels (not to mention the risks of the wildfire itself). 

![](https://www.gannett-cdn.com/experiments/usatoday/responsive/2018/ca-wildfires/img/cal-fires-1970-2017.svg)

We are interested in investigating California county-level hospitalization rates as a function of the annual number of days each county had $\text{PM}_{2.5}$ levels over the national standard.

## Related Work

A 2006 study by Dominici, Peng, and Bell showed that short-term exposure to $\text{PM}_{2.5}$ increases the risk for hospital admission for cardiovascular and respiratory diseases. Specifically, there was a short-term increase in hospital admission rates associated with $\text{PM}_{2.5}$ for heart disease, heart rhythm, heart failure, COPD, and respiratory infection; the largest association was for heart failure. In a 2009 paper, Neupane et al. found that long-term exposure to higher levels of nitrogen dioxide and $\text{PM}_{2.5}$ is significantly associated with hospitalization for community-aquired pneumonia among elderly patients in Hamilton, Ontario, Canada. Similarly, Ostro et al. found in 2008 that components of $\text{PM}_{2.5}$ were associated with several childhood respiratory diseases including pneumonia, bronchitis, and asthma among children in six California counties. Much work on the association of $\text{PM}_{2.5}$ with health outcomes focuses on birth outcomes or respiratory issues; we expand this exploration to all classifications of preventable hospitalization.

Bell et al. examine how air pollution control could not only prevent adverse health outcomes but also make a monumental economic impact. Air pollution control policy could help prevent over 156,000 deaths, 4 million asthma attacks, 300,000 children's medical visits, and almost 48,000 cases of chronic bronchitis over a twenty-year period in Santiago, Sao Paulo, and Mexico City; the economic value of these avoided health outcomes is about 21-165 billion USD. Fisk and Chan found in 2016 that using portable air cleaners led to economic benefits exceeding or far exceeding intervention costs. Thus, understanding how $\text{PM}_{2.5}$ is related to preventable hospitalizations can help California counties plan for intervention or even prevention efforts as well as budget for the impact of adverse health outcomes from wildfires.

## Initial Questions

Our primary research question is what, if any, is the effect of $\text{PM}_{2.5}$ on hospitalization rates in California? We further want to investigate how this effect differs by medical condition. Additional questions relevant to the analysis are (1) to what extent is hospitalization rate spatially or temporally correlated, and (2) to what extent is the predictor $\text{PM}_{2.5}$ spatially or temporally correlated?

## Data

We obtained our health-related data from the [California Health and Human Services Open Data Portal](https://data.chhs.ca.gov/dataset/rates-of-preventable-hospitalizations-for-selected-medical-conditions-by-county). The data contain annual hospitalization rates by county for a selection of preventable medical conditions. The rates are calculated using ICD-9 and ICD-10 codes and then standardized to the number of hospitalizations per 100,000 individuals. We obtained our air quality-related data from the [California Air Resources Board](https://www.arb.ca.gov/adam/index.html). The data include $\text{PM}_{2.5}$ levels by county. To match the granularity of our health data, we chose to use the annual days above the national 24-hour standard as our air quality metric. We also obtained county-level demographic data to control for any potential effect of demographic features on hospitalization rates; these data were obtained from the [US Census Bureau](https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t&keepList=f).

We merged the above datasets by county and year. The air quality data were only from the years 2010-2017, so we excluded any additional years from the other two datasets. Next, we checked each variable for unreasonable values. There were some values in the demographic data variables that were unreasonable (e.g. percentiles above 100\% describing a county's estimated percent of black residents); we excluded these rows.

The data were originally in long format; each row represented a county, year, and medical condition combination. We spread the data to wide format so that each medical condition had its own column containing its associated annual hospitalization rates. The new dataframe had a row for each county and year combination. This dataframe was used for all subsequent analyses. 

```{r (Xinye) packages that I will be using, message = FALSE, warning = FALSE}
library("SpatioTemporal"); library("sp"); library("mgcv") #we need "gam" function
library("ggplot2"); library("knitr"); library("dplyr"); library("ape") #moran's I
library("spdep"); library("CARBayesST")
```

```{r (Xinye) data for EDA and GAM, message = FALSE, warning=FALSE}
# Prepare data

# 1. latitude and longitude
loc = cali@data[,c(5,6,ncol(cali@data)-1,ncol(cali@data))]
loc$NAME = as.character(loc$NAME)
names(loc)[1] = "county"
loc$NAMELSAD = as.character(loc$NAMELSAD)

# 2. xy coordinates using WGS84, just in case
# source: https://rpubs.com/dasaptaerwin/19879
xy <- as.data.frame(loc[,c(3,4)])
xy <- as.data.frame(apply(xy,2,function(x){as.numeric(as.character(x))}))
cord.dec = SpatialPoints(cbind(xy$INTPTLON,-xy$INTPTLAT), 
                         proj4string=CRS("+proj=longlat"))
coord <- as.data.frame(spTransform(cord.dec, CRS("+init=epsg:32748")))

#3. combine latlong and coordinates
loc.all <- data.frame(loc,x = coord$coords.x1, y = coord$coords.x2)


#4. merge; convert lat and long to numeric 
# this is the data used for GAM, but not for CAR model

datnew <- left_join(dat,loc.all,by = "county") %>% 
  mutate(lat = as.numeric(as.character(INTPTLAT)),
         long = as.numeric(as.character(INTPTLON))) 

```

## Exploratory Data Analysis

#### 1. Spatial and temporal pattern for PM2.5
$\text{PM}_{2.5}$ levels vary across different regions with high variability in the farm region and lower variability across counties in other regions. The temporal patterns for $\text{PM}_{2.5}$ are also heterogeneous across regions and counties.

```{r (Xinye) EDA, warning = FALSE, message = FALSE}

# EDA: temporal trend in each region
plot_pm25_time <- datnew %>% group_by(year, county) %>% filter(!is.na(pm25)) %>%
  ggplot(aes(x = year, y = pm25,color = county)) +
  geom_smooth(method = "gam",formula = y~s(x,k= 5),se = FALSE,size = .5) +
  facet_wrap(.~region,ncol = 5) + 
  labs(title = "Temporal trends of PM2.5 across regions") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5,size = 10))

plot_pm25_time
```

#### Spatial autocorrelation 

Our data are correlated because of their intrinsic geographical clustering. We start with a Generalized Linear Model (GLM) which assumes independence of data and we test the existence of spatial autocorrelations among residuals via Moran's I Index. 9 out of 17 causes of the preventable hospitalization rate are spatially autocorrelated. Hospitalization causes for which we fail to detect spatial autocorrelation after accounting $\text{PM}_{2.5}$ and other covariates include angina, dehydration, diabetes short-term complications, hypertension, lower-extremity amputation, perforated appendix, uncontrolled diabetes, and prevention quality diabetes composite.

```{r (Xinye) Morans I-testing spatial autocorrelation, message = FALSE, warning = FALSE}
ca.dists <- as.matrix(dist(cbind(datnew$long, datnew$lat)))
ca.dists.inv <- 1/ca.dists
diag(ca.dists.inv) <- 0
ca.dists.inv[is.infinite(ca.dists.inv)] <- 0

# a function that returns pvalue from Moran's I index testing
moransI.pval <- function(y){
  res = rep(NA,320)
  if (! y %in% names(datnew)[8:24]) 
  {print("Outcome does not exist")}
  
  else{
    y2 = as.vector(pull(datnew[,y]))
    
    datnew_copy <- data.frame(datnew) %>% 
      dplyr::mutate(outcome_interest = y2) %>%
      dplyr::select(outcome_interest,year,age60_perc,est.black.percent,
                    bachelor_perc,pm25)
    
    fit_glm = glm(outcome_interest ~ pm25 + age60_perc + est.black.percent +
                    bachelor_perc, data = datnew_copy)
    res_glm = residuals.glm(fit_glm)
    res[as.numeric(names(res_glm))] <- res_glm 
    Moran.I(res,ca.dists.inv,na.rm = TRUE)$p.value
    #return(res)
  }
}

mI_pval <- c()

for (i in 1:17){
  mI_pval[i] <- moransI.pval(names(datnew)[7+i])
}

# these outcomes are not spatially autocorrelated
#names(datnew[8:24])[which(mI_pval > 0.05)]

```

#### Linearity of spatial and temporal patterns 

We used the Generalized Additive Model (GAM) with splines in both geographical locations and years to test the linearity of spatial and temporal trends for $\text{PM}_{2.5}$. Both the spatial and the temporal pattern of $\text{PM}_{2.5}$ are non-linear.

```{r (Xinye) gam-testing linearity of spatial and temporal trend for pm2.5, message = FALSE,warning = FALSE}

# test the spatio-temporal trend of PM2.5
gam_pm25_spacetime <- gam(pm25~s(lat,long) + s(year, k = 5),
                          data = datnew,family = gaussian)

# gam output
tb_gam_pm25_st <- summary.gam(gam_pm25_spacetime)$s.table
colnames(tb_gam_pm25_st) <- c("Estimated df", "Residual df",
                              "F-statistic","p-value")
tb_gam_pm25_st[1,4] <- "<2.2e-16"
tb_gam_pm25_st[,1:3] <- round(as.numeric(tb_gam_pm25_st[,1:3]),2)
tb_gam_pm25_st[2,4] <- 0.0012
kb_gam_pm25_st <- kable(tb_gam_pm25_st, caption = "linearity of spatial and temporal trends for PM2.5")

kb_gam_pm25_st
```

We also examine whether the spatiotemporal trend for each outcome is linear by applying the same method. It turns out that the spatial patterns are nonlinear for all outcomes whereas the temporal patterns are likely to be linear for all.

```{r (Xinye) testing linearity of spatial and temporal trend for outcomes,message = FALSE, warning = FALSE}

st.trend <- function(y,data = datnew) {
  require("mgcv");require("dplyr")
  # check whether input outcome exists
  if (! y %in% names(datnew)[8:24]) 
  {print("Outcome does not exist")}
  
  else{
    y = datnew[,y]
  #GAM
  gam_outcome_spacetime <- gam(y~s(lat,long)+s(year, k = 5),
                               data = datnew,family = gaussian)
  test_linear_trend <- summary(gam_outcome_spacetime)$s.table
  

  #return smoothness results
  return(test_linear_trend)}
}


tmp = apply(matrix(names(datnew)[8:24],ncol = 1),1, st.trend)

tb_outcome_st <- matrix(c(mean(tmp[7,] < 0.05),mean(tmp[8,] < 0.05)),ncol = 2)
colnames(tb_outcome_st) <- c("Spatial non-linearity (%)",
                             "Temporal non-linearity (%)")
kable(tb_outcome_st, caption = "Spatio-temporal trends for all outcomes")
```



## Data Analysis



#### Bayes CAR Model
To further study the overall effect of PM2.5 on preventable hospitalization, we use a Bayesian hierarchical model with random effects estimated from a Conditional Autoregressive (CAR) model. More specifically, we consider a CAR(1) model to represent the spatiotemporal random effects structure with hyperparameters from Uniform and Inverse Gamma distributions. 

Markov Chain Monte Carlo (MCMC) simulation is implemented to make the inference.  We generate 50500 MCMC samples and discard the first 500 samples. To eliminate the autocorrelations from the Markov Chain, the MCMC sample is thinned by 10 with resulting 5000 post-burn-in and thinned samples. 

The Bayes CAR model estimates the aggregated effect of PM2.5 on preventable hospitalization of different causes in California. The spatiotemporal correlation has been taken into account in estimation, and therefore, the results are more reasonable comparing to models without considerations of spatiotemporal effects.


## Results and Summary



#### CAR Model results (this should go last): need caption maybe?

```{r (Xinye) CAR model, message = FALSE, warning = FALSE}
#1. prepare data for CAR model: need to delete counties with NAs in pm25
dat_car <- datnew %>% filter(!county %in% c("Yuba","El Dorado"))

#2. W matrix with binary elements that indicate shared border between counties
W.nb <-poly2nb(cali)
W.list <- nb2listw(W.nb, style = "B")
W <- nb2mat(W.nb, style = "B")
rownames(W) = cali@data$NAME;colnames(W) = cali@data$NAME

# we have limited counties
index = c(which(is.na(match(loc.all$county,dat_car$county))))
W <- W[-index,-index]

# Shasta d.n. have any neighbor -> manually inpute the closet neighbor as 1
# make sure W is symmetric
W[12,28] <- 1; W[28,12] <- 1;W[12,14] <- 1;W[14,12] <- 1

#3. Impute missing covariate 
dat_car[which(is.na(dat_car$pm25)),c("pm25")] <- c(1,0,0,1.61,10,1,0,1,1,1,0,0,.5,.5,3.5,4,1)

#4. CAR model

# the function "car.model" takes an outcome name (character) and return the summary that includes coefficient estimate and credible interval

# default data: dat_car
car.model <- function(y,data = dat_car){
  require("knitr");require("CARBayes");require("dplyr")
  if (! y %in% names(dat_car)[8:24]) 
  {print("Outcome does not exist")}
  else{
    y2 = pull(dat_car[,y])
    
    dat_car_copy <- data.frame(dat_car) %>% 
      mutate(outcome_interest = y2) %>%
      dplyr::select(outcome_interest,year,age60_perc,est.black.percent,
             bachelor_perc,pm25)
    
    fitst_adapt <- ST.CARadaptive(outcome_interest~pm25 + age60_perc + 
                                    est.black.percent +
                                    bachelor_perc + year, 
                                  family = "gaussian",
                                  data = dat_car_copy, W = W, burnin = 500, 
                                  n.sample = 50500,
                                  thin = 10)
    #fitst_adapt$summary.results[c(2:5),c(1,2,3)]
    
    point_estimate <- unname(round(fitst_adapt$summary.results[c(2:5),1],2))
    lb <- round(fitst_adapt$summary.results[c(2:5),2],2)
    ub <- round(fitst_adapt$summary.results[c(2:5),3],2)
    CI <- noquote(paste("(",lb,",",ub,")",sep = ""))
    var_name <- c("pm25","Age>60 (%)", "Black (%)", ">Bachelor (%)")
    model_summary <- cbind(var_name, point_estimate, CI)
    colnames(model_summary) <- c("","Estimate","95% Credible Interval")
    tb <- kable(model_summary, caption = paste("Bayes CAR results for",y))
    return(tb)
  }
}

# say, we are interested in the following 3 causes 
car.model("pneumonia")
car.model("asthma_older")
car.model("asthma_young")
```


## All Ruthe's code

```{r Read in data, eval = F}
rm(list = ls())
library(tidyverse); library(lubridate); library(stringr); library(rgdal)

# read in 2010-2017 California air quality data
pm25 <- read_csv("data/pm25_annual-days-above-nat-24-hr-stnd.csv", na = "*") %>% group_by(county) %>% summarize(pm2010 = mean(pm2010, na.rm = T), pm2011 = mean(pm2011, na.rm = T), pm2012 = mean(pm2012, na.rm = T), pm2013 = mean(pm2013, na.rm = T), pm2014 = mean(pm2014, na.rm = T), pm2015 = mean(pm2015, na.rm = T), pm2016 = mean(pm2016, na.rm = T), pm2017 = mean(pm2017, na.rm = T)) %>% gather(year, pm25, pm2010:pm2017) %>% mutate(year = as.numeric(str_sub(year, 3, 6))) %>% arrange(county)
head(pm25)

demo <- read_csv("data/age_edu_race.csv")[ , -1] %>% group_by(Geography, Year) %>% filter(bachelor_perc <= 100) %>% summarize(age60_perc = mean(age60_perc, na.rm = T), bachelor_perc = mean(bachelor_perc, na.rm = T), est.white.percent = mean(est.white.percent, na.rm = T), est.black.percent = mean(est.black.percent, na.rm = T)) %>% ungroup() %>% mutate(Geography = str_sub(Geography, 1, -20)) %>% rename(county = Geography, year = Year)
head(demo)

phosp <- read_csv("data/ca-oshpd-preventablehospitalizations-county-2005-2017.csv")
ph_early <- phosp %>% filter(Year < 2016) %>% group_by(County, Year) %>% select(Year, County, PQIDescription, ObsRate_ICD9) %>% spread(PQIDescription, value = ObsRate_ICD9) %>% rename(diabetes_st = "Diabetes Short-term Complications", perf_appendix = "Perforated Appendix", diabetes_lt = "Diabetes Long-term Complications", asthma_older = "COPD or Asthma in Older Adults (Age 40+)", hypertension = "Hypertension", heart_fail = "Heart Failure", dehydration = "Dehydration", pneumonia = "Community-Acquired Pneumonia", uti = "Urinary Tract Infection", angina = "Angina without Procedure", diabetes_uc = "Uncontrolled Diabetes", asthma_young = "Asthma in Younger Adults (Age 18-39)", amputation_diab = "Lower-Extremity Amputation (Diabetes)", pq_overall = "Prevention Quality Overall Composite", pq_acute = "Prevention Quality Acute Composite", pq_chronic = "Prevention Quality Chronic Composite") %>% mutate(pq_diabetes = NA)

ph_late <- phosp %>% filter(Year >= 2016) %>% group_by(County, Year) %>% select(Year, County, PQIDescription, ObsRate_ICD10) %>% spread(PQIDescription, value = ObsRate_ICD10) %>% rename(asthma_older = "COPD or Asthma in Older Adults (Age 40+)", diabetes_st = "Diabetes Short-term Complications", perf_appendix = "Perforated Appendix", diabetes_lt = "Diabetes Long-term Complications", hypertension = "Hypertension", heart_fail = "Heart Failure", dehydration = "Dehydration", pneumonia = "Community-Acquired Pneumonia", uti = "Urinary Tract Infection", diabetes_uc = "Uncontrolled Diabetes", asthma_young = "Asthma in Younger Adults (Age 18-39)", amputation_diab = "Lower-Extremity Amputation (Diabetes)", pq_overall = "Prevention Quality Overall Composite", pq_acute = "Prevention Quality Acute Composite", pq_chronic = "Prevention Quality Chronic Composite", pq_diabetes = "Prevention Quality Diabetes Composite") %>% mutate(angina = NA)

phosp <- rbind(ph_early, ph_late) %>% arrange(County) %>% rename(county = County, year = Year)

# label counties by clustering algorithm
dat <- demo %>% left_join(pm25, by = c("county", "year")) %>% left_join(phosp, by = c("county", "year")) %>% mutate(region = NA, region = replace(region, county %in% c("Del Norte", "Humboldt", "Mendocino", "Lake", "Siskiyou", "Trinity", "Shasta", "Tehema", "Butte", "Yuba",
"Sacramento", "Modoc", "Lassen"), "northern"), region = replace(region, county %in% c("Sonoma", "Marin", "Solano", "Napa", "Yolo", "Contra Costa", "Alameda", "San Mateo", "Santa Clara", "Santa Cruz", "San Benito", "Monterey", "San Luis Obispo", "Santa Barbara", "Ventura", "Orange", "San Diego", "Riverside", "Sierra", "Nevada", "Placer", "El Dorado", "Amador", "Mono"), "coastal"), region = replace(region, county %in% c("Alpine", "Calaveras", "Tuolumne", "Mariposa", "Inyo"), "motherlode"), region = replace(region, county %in% c("Glenn", "Colusa", "Sutter", "San Joaquin", "Stanislaus", "Merced", "Madera", "Fresno", "Kings", "Tulare", "Kern", "Los Angeles", "San Bernardino"), "farm"), region = replace(region, county == "San Francisco", "sanfrancisco"), region = replace(region, county == "Imperial", "imperial"))

# # label counties by CDSS groups
# dat <- demo %>% left_join(pm25, by = c("county", "year")) %>% left_join(phosp, by = c("county", "year")) %>% mutate(region = NA, region = replace(region, county %in% c("Alameda", "Contra Costa", "Marin", "Napa", "San Francisco", "San Mateo", "Santa Clara", "Santa Cruz", "Solano", "Sonoma"), "bayarea"), region = replace(region, county %in% c("Orange", "Riverside", "San Bernardino", "San Diego", "Santa Barbara", "Ventura"), "socal"), region = replace(region, county == "Los Angeles", "losangeles"), region = replace(region, county %in% c("Fresno", "Imperial", "Kern", "Kings", "Madera", "Merced", "Monterey", "San Benito", "San Joaquin", "San Luis Obispo", "Stanislaus", "Tulare"), "csfarm"), region = replace(region, county %in% c("Alpine", "Amador", "Butte", "Calaveras", "Del Norte", "Glenn", "Humboldt", "Inyo", "Lake", "Lassen", "Mariposa", "Mendocino", "Modoc", "Mono", "Nevada", "Plumas", "Shasta", "Sierra", "Siskiyou", "Tehama", "Trinity", "Tuolumne"), "nmountain"), region = replace(region, county %in% c("Colusa", "El Dorado", "Placer", "Sacramento", "Sutter", "Yolo", "Yuba"), "centralvalley"))

# save(dat, file = "data/dat.R")
rm(list = setdiff(ls(), "dat"))
```

```{r CA visualizations}
rm(list = ls())
library(tidyverse); library(lubridate); library(stringr); library(rgdal)

load("data/dat.R")
cali <- readOGR(dsn = "data/CA_Counties", layer = "CA_Counties_TIGER2016")
cali$NAME <- as.character(cali$NAME)
# plot(cali)

caplot <- function(yr, var, cutoffs = NULL) #year: numeric input, var: character input
{
  df <- dat %>% filter(year == yr) %>% select(county, var)
  map <- merge(cali, df, by.x = "NAME", by.y = "county", all.x = T)
  if (length(cutoffs) == 0)
  {
    brks <- quantile(map@data[ , var], seq(0, 1, by = 0.2), na.rm = T)
    mycols <- c("rosybrown1", "palevioletred1", "deeppink1", "magenta3", "purple4")
  } else {
    brks <- cutoffs
    mycols <- c("cornsilk1", "goldenrod1", "darkorange", "firebrick2", "darkred")
  }
  cols <- as.character(cut(map@data[ , var], breaks = brks, labels = mycols))
  
  plot(map, col = "grey77", border = NA, main = yr, cex.main = 2)
  plot(map, col = cols, add = T, border = NA)
}


pmplot <- function(yr) # special function for PM 2.5 plots
{
  df <- dat %>% filter(year == yr) %>% select(county, pm25)
  map <- merge(cali, df, by.x = "NAME", by.y = "county", all.x = T)
  cols <- as.character(cut(map@data[ , "pm25"], breaks = c(0, 3, 6, 10, 20, 100), include.lowest = T, labels = c("darkseagreen1", "mediumspringgreen", "darkturquoise", "dodgerblue2", "navy")))
  
  plot(map, col = "grey77", border = NA, main = yr, cex.main = 2)
  plot(map, col = cols, add = T, border = NA)
  # legend(x = -12890659, y = 4927837, legend = levels(cut(map@data[ , "pm25"], breaks = c(0, 3, 6, 10, 20, 100), include.lowest = T)), fill = c("darkseagreen1", "mediumspringgreen", "darkturquoise", "dodgerblue2", "navy"), cex = 1)
}

bigplot <- function(var, cut = NULL, omit = F)
{
  if (length(cut) == 0)
  {
    par(oma = c(4, 0, 0, 0), mar = c(0.5, 0.5, 1.5, 0.5), mfrow = c(2, 4))
    caplot(2010, var)
    caplot(2011, var)
    caplot(2012, var)
    caplot(2013, var)
    caplot(2014, var)
    caplot(2015, var)
    if (omit == F)
    {
      caplot(2016, var)
      caplot(2017, var)
    }
    par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
    plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
    legend("bottom", legend = c("[0-20th percentile]", "(20-40th percentile]", "(40-60th percentile]", "(60-80th percentile]", "(80-100th percentile]"), fill = c("rosybrown1", "palevioletred1", "deeppink1", "magenta3", "purple4"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", cex = 2)
  } else {
    par(oma = c(4, 0, 0, 0), mar = c(0.5, 0.5, 1.5, 0.5), mfrow = c(2, 4))
    caplot(2010, var, cutoffs = cut)
    caplot(2011, var, cutoffs = cut)
    caplot(2012, var, cutoffs = cut)
    caplot(2013, var, cutoffs = cut)
    caplot(2014, var, cutoffs = cut)
    caplot(2015, var, cutoffs = cut)
    caplot(2016, var, cutoffs = cut)
    caplot(2017, var, cutoffs = cut)
    par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
    plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
    legend("bottom", legend = levels(cut(unlist(dat[ , var]), breaks = cut, include.lowest = T)), fill = c("cornsilk1", "goldenrod1", "darkorange", "firebrick2", "darkred"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", cex = 2)
  }
}
```

## Days Over National $\text{PM}_{2.5}$ Standard by County Over Time

```{r, fig.height = 9, fig.width = 14}
par(oma = c(4, 0, 0, 0), mar = c(0.5, 0.5, 1.5, 0.5), mfrow = c(2, 4))
pmplot(2010)
pmplot(2011)
pmplot(2012)
pmplot(2013)
pmplot(2014)
pmplot(2015)
pmplot(2016)
pmplot(2017)
par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", legend = levels(cut(dat$pm25, breaks = c(0, 5, 10, 20, 30, 100), include.lowest = T)), fill = c("darkseagreen1", "mediumspringgreen", "darkturquoise", "dodgerblue2", "navy"), xpd = TRUE, horiz = TRUE, inset = c(0, 
    0), bty = "n", cex = 2)
```


## Health Outcomes Over Time

### Angina
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("angina", cut = c(0, 10, 20, 30, 45, 65))
bigplot("angina", omit = T)
```

*No `angina` data for 2016 and 2017

### Asthma (in Younger Adults)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("asthma_young", cut = c(0, 10, 20, 30, 45, 125))
bigplot("asthma_young")
```

### Asthma/COPD (in Older Adults)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("asthma_older", cut = c(100, 250, 400, 600, 800, 1000))
bigplot("asthma_older")
```

### Pneumonia
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("pneumonia", cut = c(50, 100, 200, 300, 400, 550))
bigplot("pneumonia")
```

### Dehydration
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("dehydration", cut = c(30, 80, 100, 150, 200, 320))
bigplot("dehydration")
```

### Diabetes (Short-Term Complications)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("diabetes_st", cut = c(15, 45, 75, 100, 120, 150))
bigplot("diabetes_st")
```

### Diabetes (Long-Term Complications)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("diabetes_lt", cut = c(20, 50, 80, 100, 150, 230))
bigplot("diabetes_lt")
```

### Diabetes (Uncontrolled)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("diabetes_uc", cut = c(0, 5, 15, 30, 60, 100))
bigplot("diabetes_uc")
```

### Amputation (from Diabetes)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("amputation_diab", cut = c(0, 10, 20, 30, 45, 65))
bigplot("amputation_diab")
```

### Heart Failure
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("heart_fail", cut = c(120, 200, 300, 400, 500, 600))
bigplot("heart_fail")
```

### Hypertension
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("hypertension", cut = c(0, 10, 25, 40, 60, 120))
bigplot("hypertension")
```

### Perforated Appendix
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("perf_appendix", cut = c(15, 35, 50, 100, 500, 700))
bigplot("perf_appendix")
```

*Why such a high increase in 2016-2017? Maybe data collection different?*

## UTI
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("uti", cut = c(35, 100, 125, 150, 200, 270))
bigplot("uti")
```

#manipulating Ruthe's data for ST modeling_XL
```{r, eval = F}
library("SpatioTemporal")
library("sp")

#latitude and longitude
loc = cali@data[,c(5,6,ncol(cali@data)-1,ncol(cali@data))]
loc$NAME = as.character(loc$NAME)
names(loc)[1] = "county"
loc$NAMELSAD = as.character(loc$NAMELSAD)

#xy coordinates using WGS84
#source: https://rpubs.com/dasaptaerwin/19879
xy <- as.data.frame(loc[,c(3,4)])
xy <- as.data.frame(apply(xy,2,function(x){as.numeric(as.character(x))}))
cord.dec = SpatialPoints(cbind(xy$INTPTLON,-xy$INTPTLAT), 
                         proj4string=CRS("+proj=longlat"))
coord <- as.data.frame(spTransform(cord.dec, CRS("+init=epsg:32748")))

#combine latlong and coordinates
loc.all <- data.frame(loc,x = coord$coords.x1, y = coord$coords.x2)

#merge; county as a factor
datnew = left_join(dat,loc.all,by = "county") %>% 
  mutate(ID = factor(county)) %>%
  rename(lat = INTPTLAT, long = INTPTLON)

#outcome data for all categories
outcome_data <- datnew %>%  
  select(-age60_perc,-bachelor_perc,
         -est.white.percent,-est.black.percent,-pm25)

#Let's say we pick dehydration as an outcome
#dehydration only, wide format
#matrix
outcome_dehy <- outcome_data %>% select(ID,year, dehydration) %>%
  spread(key = ID,value = dehydration)

outcome_dehydration <- as.matrix(outcome_dehy[,-1],nrow = 8)
rownames(outcome_dehydration) = c(2010,2011,2012,2013,2014,2015,2016,2017)
colnames(outcome_dehydration) = unique(datnew$county)

#convarites (non-time-varying): I chose 2015 (this may change later)
#data.frame
covariate <- datnew %>% filter(year == 2015)  %>%
  select(ID,x,y,lat,long,age60_perc,bachelor_perc,
         est.white.percent,est.black.percent) %>%
  mutate(type = factor(rep(1,n())))

#check covaraite data is ok
#stCheckCovars(covariate, ID.unique = character(0)) #ok

#time-varying covariate: pm25
#matrix
stcov = datnew %>% select(year,ID,pm25) %>% spread(key = ID,value = pm25)
stcov <- as.matrix(stcov[,-1],nrow = 8)
rownames(stcov) = c(2010,2011,2012,2013,2014,2015,2016,2017)
colnames(stcov) = unique(datnew$county)

#list to create STdata object
st_dehy <- list(obs = outcome_dehydration, X = covariate,
               stcov = stcov)

#STdata Object!
st_dehy_obj <- createSTdata(st_dehy$obs, st_dehy$X, 
                            SpatioTemporal = list(st_pm2.5 = stcov))
# plot(st_dehy_obj,"loc")
# print(st_dehy_obj)

#try to create a STmodel: not working
LUR <- list(~est.black.percent + age60_perc + bachelor_perc)
ST <- "pm25"
locations <- list(coords = c("x","y"), long.lat = c("long", "lat"),others = "type")
cov.beta <- list(covf = "exp", nugget = FALSE)
cov.nu <- list(covf = "exp", nugget = ~type, random.effect = FALSE)
createSTmodel(st_dehy_obj, LUR = LUR, ST = ST, cov.beta = cov.beta, 
              cov.nu = cov.nu, locations = locations)


```

Limitation: lot of zeros for days above national $\text{PM}_{2.5}$ standard






