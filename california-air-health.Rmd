---
title: "Something Clever"
author: "Ruthe Huang, Xinye Li, Emily Scott"
date: "December 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, fig.align = "center")
```

## Motivation and Overview

Wildfires are a natural, annual occurrence in California. However, climate change has helped California's wildfires more intense, with the warm and dry conditions creating ideal conditions for wildfire. According to the Environmental Protection Agency, the state of California is becoming warmer as a whole; preceding both 2017 and 2018 wildfires were some of the state's highest temperatures in history.

Predictably, large fires have become more common in California, as seen in the chart below. Each bar represents a single fire, and the bar height represents the size of areas burned, in acres.

![](https://www.gannett-cdn.com/experiments/usatoday/responsive/2018/ca-wildfires/img/cal-fires-1970-2017.svg)

Fires now tend to be associated with more human risk due to urban expansion into high-risk fire zones. California's population increasingly tends to live in proximity to high-risk fire corridors; as a result, wildfires more frequently devastate settled areas. The number of properties at risk of wildfire threat is estimated by Villanova University to be nearly 7 million, a more than 1000% increase in the number of homes and developed land in areas prone to wildfires since 1940. California's 2018 Camp Fire completely destroyed Paradise, CA, the second-largest city in Butte County with a population of about 26,682. A 2017 Verisk risk analysis puts 15% -- or over 2 million -- of California's homes in high or extremely high wildfire risk zones and another 12% in moderate risk areas; this means more than a quarter of the state's homes are at moderate to extremely high risk of being damaged in a wildfire.

The extent of risk undeniably poses a huge task for California firefighters. Historically, Southern California firefighters were able to depend on help from Northern California partners, since Northern California would have already started to see rainfall or even snow. However with statewide climate change, both northern and southern California fires continue to be disastrous and necessitate abundant resources.

## Related Work

A 2006 study by Dominici, Peng, and Bell showed that short-term exposure to $\text{PM}_{2.5}$ increases the risk for hospital admission for cardiovascular and respiratory diseases. Specifically, there was a short-term increase in hospital admission rates associated with $\text{PM}_{2.5}$  for heart disease, heart rhythm, heart failure, COPD, and respiratory infection; the largest association was for heart failure. In a 2009 paper, Neupane et al. found that long-term exposure to higher levels of nitrogen dioxide and $\text{PM}_{2.5}$ is significantly associated with hospitalization for community-aquired pneumonia among elderly patients in Hamilton, Ontario, Canada. Similarly, Ostro et al. found in 2008 that components of $\text{PM}_{2.5}$ were associated with several childhood respiratory diseases including pneumonia, bronchitis, and asthma among children in six California counties. Much work on the association of $\text{PM}_{2.5}$ with health outcomes focuses on birth outcomes or respiratory issues; we expand this exploration to all classifications of preventable hospitalization.

Bell et al. examine how air pollution control could not only prevent adverse health outcomes but also make a monumental economic impact. Air pollution control policy could help prevent over 156,000 deaths, 4 million asthma attacks, 300,000 children's medical visits, and almost 48,000 cases of chronic bronchitis over a twenty-year period in Santiago, Sao Paulo, and Mexico City; the economic value of these avoided health outcomes is about 21-165 billion USD. Fisk and Chan found in 2016 that using portable air cleaners led to economic benefits exceeding or far exceeding intervention costs. Thus, understanding how $\text{PM}_{2.5}$ is related to preventable hospitalizations can help California counties plan for intervention or even prevention efforts as well as budget for the impact of adverse health outcomes from wildfires.

## Initial Questions

## Data


```{r (Xinye) packages that I will be using, message=FALSE,warning=FALSE}
library("SpatioTemporal"); library("sp"); library("mgcv") #we need "gam" function
library("ggplot2"); library("knitr"); library("dplyr"); library("ape") #moran's I
library("spdep"); library("CARBayesST")
```


```{r (Xinye) data for EDA and GAM, message = FALSE, warning=FALSE}
# prepare data

#1. latitude and longitude
loc = cali@data[,c(5,6,ncol(cali@data)-1,ncol(cali@data))]
loc$NAME = as.character(loc$NAME)
names(loc)[1] = "county"
loc$NAMELSAD = as.character(loc$NAMELSAD)

#2. xy coordinates using WGS84, just in case
# source: https://rpubs.com/dasaptaerwin/19879
xy <- as.data.frame(loc[,c(3,4)])
xy <- as.data.frame(apply(xy,2,function(x){as.numeric(as.character(x))}))
cord.dec = SpatialPoints(cbind(xy$INTPTLON,-xy$INTPTLAT), 
                         proj4string=CRS("+proj=longlat"))
coord <- as.data.frame(spTransform(cord.dec, CRS("+init=epsg:32748")))

#3. combine latlong and coordinates
loc.all <- data.frame(loc,x = coord$coords.x1, y = coord$coords.x2)


#4. merge; convert lat and long to numeric 
# this is the data used for GAM, but not for CAR model

datnew <- left_join(dat,loc.all,by = "county") %>% 
  mutate(lat = as.numeric(as.character(INTPTLAT)),
         long = as.numeric(as.character(INTPTLON))) 

```

## Exploratory Data Analysis

#### 1. Spatial and temporal pattern for PM2.5
PM2.5 levels vary across different regions with higher variability in the Farm region and relatively similar amount across counties in other regions. The temporal patterns for PM2.5 are also heterogeneous across regions and counties.

```{r (Xinye) EDA, warning = FALSE, message = FALSE}

# EDA: temporal trend in each region
plot_pm25_time <- datnew %>% group_by(year, county) %>% filter(!is.na(pm25)) %>%
  ggplot(aes(x = year, y = pm25,color = county)) +
  geom_smooth(method = "gam",formula = y~s(x,k= 5),se = FALSE,size = .5) +
  facet_wrap(.~region,ncol = 5) + 
  labs(title = "Temporal trends of PM2.5 across regions") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5,size = 10))

plot_pm25_time
```


#### Spatial autocorrelation 

Our data is correlated in nature because of the intrinsic geographical clustering. We start with a Generalized Linear Model (GLM) which assumes independence of data, and we test the existence of spatial autocorrelations among residuals via Moran's I Index. 9 out of 17 causes of the preventable hospitalization rate are spatially autocorrelated. Causes that we fail to detect for spatial autocorrelation after accounting for the effect from PM2.5 and other covariates include Angina, Dehydration, Diabetes Short-term Complications, Hypertension, Lower-Extremity Amputation, Perforated Appendix, Uncontrolled Diabetes, and Prevention Quality Diabetes Composite.

```{r (Xinye) Morans I-testing spatial autocorrelation, message = FALSE, warning = FALSE}
ca.dists <- as.matrix(dist(cbind(datnew$long, datnew$lat)))
ca.dists.inv <- 1/ca.dists
diag(ca.dists.inv) <- 0
ca.dists.inv[is.infinite(ca.dists.inv)] <- 0

# a function that returns pvalue from Moran's I index testing
moransI.pval <- function(y){
  res = rep(NA,320)
  if (! y %in% names(datnew)[8:24]) 
  {print("Outcome does not exist")}
  
  else{
    y2 = as.vector(pull(datnew[,y]))
    
    datnew_copy <- data.frame(datnew) %>% 
      dplyr::mutate(outcome_interest = y2) %>%
      dplyr::select(outcome_interest,year,age60_perc,est.black.percent,
                    bachelor_perc,pm25)
    
    fit_glm = glm(outcome_interest ~ pm25 + age60_perc + est.black.percent +
                    bachelor_perc, data = datnew_copy)
    res_glm = residuals.glm(fit_glm)
    res[as.numeric(names(res_glm))] <- res_glm 
    Moran.I(res,ca.dists.inv,na.rm = TRUE)$p.value
    #return(res)
  }
}

mI_pval <- c()

for (i in 1:17){
  mI_pval[i] <- moransI.pval(names(datnew)[7+i])
}

# these outcomes are not spatially autocorrelated
#names(datnew[8:24])[which(mI_pval > 0.05)]

```




#### Linearity of spatial and temporal patterns 

We used the Generalized Additive Model (GAM) with splines in both geographical locations and years to test the linearity of spatial and temporal trends for PM2.5. Both the spatial and the temporal pattern of PM2.5 are non-linear.

```{r (Xinye) gam-testing linearity of spatial and temporal trend for pm2.5, message = FALSE,warning = FALSE}

# test the spatio-temporal trend of PM2.5
gam_pm25_spacetime <- gam(pm25~s(lat,long) + s(year, k = 5),
                          data = datnew,family = gaussian)

# gam output
tb_gam_pm25_st <- summary.gam(gam_pm25_spacetime)$s.table
colnames(tb_gam_pm25_st) <- c("Estimated df", "Residual df",
                              "F-statistic","p-value")
tb_gam_pm25_st[1,4] <- "<2.2e-16"
tb_gam_pm25_st[,1:3] <- round(as.numeric(tb_gam_pm25_st[,1:3]),2)
tb_gam_pm25_st[2,4] <- 0.0012
kb_gam_pm25_st <- kable(tb_gam_pm25_st, caption = "linearity of spatial and temporal trends for PM2.5")

kb_gam_pm25_st
```


We also examine whether the spatiotemporal trend for each outcome is linear by applying the same method. It turns out that the spatial patterns are nonlinear for all outcomes whereas the temporal patterns are likely to be linear for all.

```{r (Xinye) testing linearity of spatial and temporal trend for outcomes,message = FALSE, warning = FALSE}

st.trend <- function(y,data = datnew) {
  require("mgcv");require("dplyr")
  # check whether input outcome exists
  if (! y %in% names(datnew)[8:24]) 
  {print("Outcome does not exist")}
  
  else{
    y = datnew[,y]
  #GAM
  gam_outcome_spacetime <- gam(y~s(lat,long)+s(year, k = 5),
                               data = datnew,family = gaussian)
  test_linear_trend <- summary(gam_outcome_spacetime)$s.table
  

  #return smoothness results
  return(test_linear_trend)}
}


tmp = apply(matrix(names(datnew)[8:24],ncol = 1),1, st.trend)

tb_outcome_st <- matrix(c(mean(tmp[7,] < 0.05),mean(tmp[8,] < 0.05)),ncol = 2)
colnames(tb_outcome_st) <- c("Spatial non-linearity (%)",
                             "Temporal non-linearity (%)")
kable(tb_outcome_st, caption = "Spatio-temporal trends for all outcomes")
```


## Data Analysis


#### CAR Model (Xinye): explain what it is and why



## Results and Summary

#### CAR Model results (this should go last): need caption maybe?

```{r (Xinye) CAR model, message = FALSE, warning = FALSE}
#1. prepare data for CAR model: need to delete counties with NAs in pm25
dat_car <- datnew %>% filter(!county %in% c("Yuba","El Dorado"))

#2. W matrix with binary elements that indicate shared border between counties
W.nb <-poly2nb(cali)
W.list <- nb2listw(W.nb, style = "B")
W <- nb2mat(W.nb, style = "B")
rownames(W) = cali@data$NAME;colnames(W) = cali@data$NAME

# we have limited counties
index = c(which(is.na(match(loc.all$county,dat_car$county))))
W <- W[-index,-index]

# Shasta d.n. have any neighbor -> manually inpute the closet neighbor as 1
# make sure W is symmetric
W[12,28] <- 1; W[28,12] <- 1;W[12,14] <- 1;W[14,12] <- 1

#3. Impute missing covariate 
dat_car[which(is.na(dat_car$pm25)),c("pm25")] <- c(1,0,0,1.61,10,1,0,1,1,1,0,0,.5,.5,3.5,4,1)

#4. CAR model

# the function "car.model" takes an outcome name (character) and return the summary that includes coefficient estimate and credible interval

# default data: dat_car
car.model <- function(y,data = dat_car){
  require("knitr");require("CARBayes");require("dplyr")
  if (! y %in% names(dat_car)[8:24]) 
  {print("Outcome does not exist")}
  else{
    y2 = pull(dat_car[,y])
    
    dat_car_copy <- data.frame(dat_car) %>% 
      mutate(outcome_interest = y2) %>%
      dplyr::select(outcome_interest,year,age60_perc,est.black.percent,
             bachelor_perc,pm25)
    
    fitst_adapt <- ST.CARadaptive(outcome_interest~pm25 + age60_perc + 
                                    est.black.percent +
                                    bachelor_perc + year, 
                                  family = "gaussian",
                                  data = dat_car_copy, W = W, burnin = 500, 
                                  n.sample = 50500,
                                  thin = 10)
    #fitst_adapt$summary.results[c(2:5),c(1,2,3)]
    
    point_estimate <- unname(round(fitst_adapt$summary.results[c(2:5),1],2))
    lb <- round(fitst_adapt$summary.results[c(2:5),2],2)
    ub <- round(fitst_adapt$summary.results[c(2:5),3],2)
    CI <- noquote(paste("(",lb,",",ub,")",sep = ""))
    var_name <- c("pm25","Age>60 (%)", "Black (%)", ">Bachelor (%)")
    model_summary <- cbind(var_name, point_estimate, CI)
    colnames(model_summary) <- c("","Estimate","95% Credible Interval")
    tb <- kable(model_summary)
    return(tb)
  }
}

# we need to decide which outcome to present
#car.model("diabetes_lt")
```


## All Ruthe's code

```{r Read in data, eval = F}
rm(list = ls())
library(tidyverse); library(lubridate); library(stringr); library(rgdal)

# read in 2010-2017 California air quality data
pm25 <- read_csv("data/pm25_annual-days-above-nat-24-hr-stnd.csv", na = "*") %>% group_by(county) %>% summarize(pm2010 = mean(pm2010, na.rm = T), pm2011 = mean(pm2011, na.rm = T), pm2012 = mean(pm2012, na.rm = T), pm2013 = mean(pm2013, na.rm = T), pm2014 = mean(pm2014, na.rm = T), pm2015 = mean(pm2015, na.rm = T), pm2016 = mean(pm2016, na.rm = T), pm2017 = mean(pm2017, na.rm = T)) %>% gather(year, pm25, pm2010:pm2017) %>% mutate(year = as.numeric(str_sub(year, 3, 6))) %>% arrange(county)
head(pm25)

demo <- read_csv("data/age_edu_race.csv")[ , -1] %>% group_by(Geography, Year) %>% filter(bachelor_perc <= 100) %>% summarize(age60_perc = mean(age60_perc, na.rm = T), bachelor_perc = mean(bachelor_perc, na.rm = T), est.white.percent = mean(est.white.percent, na.rm = T), est.black.percent = mean(est.black.percent, na.rm = T)) %>% ungroup() %>% mutate(Geography = str_sub(Geography, 1, -20)) %>% rename(county = Geography, year = Year)
head(demo)

phosp <- read_csv("data/ca-oshpd-preventablehospitalizations-county-2005-2017.csv")
ph_early <- phosp %>% filter(Year < 2016) %>% group_by(County, Year) %>% select(Year, County, PQIDescription, ObsRate_ICD9) %>% spread(PQIDescription, value = ObsRate_ICD9) %>% rename(diabetes_st = "Diabetes Short-term Complications", perf_appendix = "Perforated Appendix", diabetes_lt = "Diabetes Long-term Complications", asthma_older = "COPD or Asthma in Older Adults (Age 40+)", hypertension = "Hypertension", heart_fail = "Heart Failure", dehydration = "Dehydration", pneumonia = "Community-Acquired Pneumonia", uti = "Urinary Tract Infection", angina = "Angina without Procedure", diabetes_uc = "Uncontrolled Diabetes", asthma_young = "Asthma in Younger Adults (Age 18-39)", amputation_diab = "Lower-Extremity Amputation (Diabetes)", pq_overall = "Prevention Quality Overall Composite", pq_acute = "Prevention Quality Acute Composite", pq_chronic = "Prevention Quality Chronic Composite") %>% mutate(pq_diabetes = NA)

ph_late <- phosp %>% filter(Year >= 2016) %>% group_by(County, Year) %>% select(Year, County, PQIDescription, ObsRate_ICD10) %>% spread(PQIDescription, value = ObsRate_ICD10) %>% rename(asthma_older = "COPD or Asthma in Older Adults (Age 40+)", diabetes_st = "Diabetes Short-term Complications", perf_appendix = "Perforated Appendix", diabetes_lt = "Diabetes Long-term Complications", hypertension = "Hypertension", heart_fail = "Heart Failure", dehydration = "Dehydration", pneumonia = "Community-Acquired Pneumonia", uti = "Urinary Tract Infection", diabetes_uc = "Uncontrolled Diabetes", asthma_young = "Asthma in Younger Adults (Age 18-39)", amputation_diab = "Lower-Extremity Amputation (Diabetes)", pq_overall = "Prevention Quality Overall Composite", pq_acute = "Prevention Quality Acute Composite", pq_chronic = "Prevention Quality Chronic Composite", pq_diabetes = "Prevention Quality Diabetes Composite") %>% mutate(angina = NA)

phosp <- rbind(ph_early, ph_late) %>% arrange(County) %>% rename(county = County, year = Year)

# label counties by clustering algorithm
dat <- demo %>% left_join(pm25, by = c("county", "year")) %>% left_join(phosp, by = c("county", "year")) %>% mutate(region = NA, region = replace(region, county %in% c("Del Norte", "Humboldt", "Mendocino", "Lake", "Siskiyou", "Trinity", "Shasta", "Tehema", "Butte", "Yuba",
"Sacramento", "Modoc", "Lassen"), "northern"), region = replace(region, county %in% c("Sonoma", "Marin", "Solano", "Napa", "Yolo", "Contra Costa", "Alameda", "San Mateo", "Santa Clara", "Santa Cruz", "San Benito", "Monterey", "San Luis Obispo", "Santa Barbara", "Ventura", "Orange", "San Diego", "Riverside", "Sierra", "Nevada", "Placer", "El Dorado", "Amador", "Mono"), "coastal"), region = replace(region, county %in% c("Alpine", "Calaveras", "Tuolumne", "Mariposa", "Inyo"), "motherlode"), region = replace(region, county %in% c("Glenn", "Colusa", "Sutter", "San Joaquin", "Stanislaus", "Merced", "Madera", "Fresno", "Kings", "Tulare", "Kern", "Los Angeles", "San Bernardino"), "farm"), region = replace(region, county == "San Francisco", "sanfrancisco"), region = replace(region, county == "Imperial", "imperial"))

# # label counties by CDSS groups
# dat <- demo %>% left_join(pm25, by = c("county", "year")) %>% left_join(phosp, by = c("county", "year")) %>% mutate(region = NA, region = replace(region, county %in% c("Alameda", "Contra Costa", "Marin", "Napa", "San Francisco", "San Mateo", "Santa Clara", "Santa Cruz", "Solano", "Sonoma"), "bayarea"), region = replace(region, county %in% c("Orange", "Riverside", "San Bernardino", "San Diego", "Santa Barbara", "Ventura"), "socal"), region = replace(region, county == "Los Angeles", "losangeles"), region = replace(region, county %in% c("Fresno", "Imperial", "Kern", "Kings", "Madera", "Merced", "Monterey", "San Benito", "San Joaquin", "San Luis Obispo", "Stanislaus", "Tulare"), "csfarm"), region = replace(region, county %in% c("Alpine", "Amador", "Butte", "Calaveras", "Del Norte", "Glenn", "Humboldt", "Inyo", "Lake", "Lassen", "Mariposa", "Mendocino", "Modoc", "Mono", "Nevada", "Plumas", "Shasta", "Sierra", "Siskiyou", "Tehama", "Trinity", "Tuolumne"), "nmountain"), region = replace(region, county %in% c("Colusa", "El Dorado", "Placer", "Sacramento", "Sutter", "Yolo", "Yuba"), "centralvalley"))

# save(dat, file = "data/dat.R")
rm(list = setdiff(ls(), "dat"))
```

```{r CA visualizations}
rm(list = ls())
library(tidyverse); library(lubridate); library(stringr); library(rgdal)

load("data/dat.R")
cali <- readOGR(dsn = "data/CA_Counties", layer = "CA_Counties_TIGER2016")
cali$NAME <- as.character(cali$NAME)
# plot(cali)

caplot <- function(yr, var, cutoffs = NULL) #year: numeric input, var: character input
{
  df <- dat %>% filter(year == yr) %>% select(county, var)
  map <- merge(cali, df, by.x = "NAME", by.y = "county", all.x = T)
  if (length(cutoffs) == 0)
  {
    brks <- quantile(map@data[ , var], seq(0, 1, by = 0.2), na.rm = T)
    mycols <- c("rosybrown1", "palevioletred1", "deeppink1", "magenta3", "purple4")
  } else {
    brks <- cutoffs
    mycols <- c("cornsilk1", "goldenrod1", "darkorange", "firebrick2", "darkred")
  }
  cols <- as.character(cut(map@data[ , var], breaks = brks, labels = mycols))
  
  plot(map, col = "grey77", border = NA, main = yr, cex.main = 2)
  plot(map, col = cols, add = T, border = NA)
}


pmplot <- function(yr) # special function for PM 2.5 plots
{
  df <- dat %>% filter(year == yr) %>% select(county, pm25)
  map <- merge(cali, df, by.x = "NAME", by.y = "county", all.x = T)
  cols <- as.character(cut(map@data[ , "pm25"], breaks = c(0, 3, 6, 10, 20, 100), include.lowest = T, labels = c("darkseagreen1", "mediumspringgreen", "darkturquoise", "dodgerblue2", "navy")))
  
  plot(map, col = "grey77", border = NA, main = yr, cex.main = 2)
  plot(map, col = cols, add = T, border = NA)
  # legend(x = -12890659, y = 4927837, legend = levels(cut(map@data[ , "pm25"], breaks = c(0, 3, 6, 10, 20, 100), include.lowest = T)), fill = c("darkseagreen1", "mediumspringgreen", "darkturquoise", "dodgerblue2", "navy"), cex = 1)
}

bigplot <- function(var, cut = NULL, omit = F)
{
  if (length(cut) == 0)
  {
    par(oma = c(4, 0, 0, 0), mar = c(0.5, 0.5, 1.5, 0.5), mfrow = c(2, 4))
    caplot(2010, var)
    caplot(2011, var)
    caplot(2012, var)
    caplot(2013, var)
    caplot(2014, var)
    caplot(2015, var)
    if (omit == F)
    {
      caplot(2016, var)
      caplot(2017, var)
    }
    par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
    plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
    legend("bottom", legend = c("[0-20th percentile]", "(20-40th percentile]", "(40-60th percentile]", "(60-80th percentile]", "(80-100th percentile]"), fill = c("rosybrown1", "palevioletred1", "deeppink1", "magenta3", "purple4"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", cex = 2)
  } else {
    par(oma = c(4, 0, 0, 0), mar = c(0.5, 0.5, 1.5, 0.5), mfrow = c(2, 4))
    caplot(2010, var, cutoffs = cut)
    caplot(2011, var, cutoffs = cut)
    caplot(2012, var, cutoffs = cut)
    caplot(2013, var, cutoffs = cut)
    caplot(2014, var, cutoffs = cut)
    caplot(2015, var, cutoffs = cut)
    caplot(2016, var, cutoffs = cut)
    caplot(2017, var, cutoffs = cut)
    par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
    plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
    legend("bottom", legend = levels(cut(unlist(dat[ , var]), breaks = cut, include.lowest = T)), fill = c("cornsilk1", "goldenrod1", "darkorange", "firebrick2", "darkred"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", cex = 2)
  }
}
```

## Days Over National $\text{PM}_{2.5}$ Standard by County Over Time

```{r, fig.height = 9, fig.width = 14}
par(oma = c(4, 0, 0, 0), mar = c(0.5, 0.5, 1.5, 0.5), mfrow = c(2, 4))
pmplot(2010)
pmplot(2011)
pmplot(2012)
pmplot(2013)
pmplot(2014)
pmplot(2015)
pmplot(2016)
pmplot(2017)
par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", legend = levels(cut(dat$pm25, breaks = c(0, 5, 10, 20, 30, 100), include.lowest = T)), fill = c("darkseagreen1", "mediumspringgreen", "darkturquoise", "dodgerblue2", "navy"), xpd = TRUE, horiz = TRUE, inset = c(0, 
    0), bty = "n", cex = 2)
```


## Health Outcomes Over Time

### Angina
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("angina", cut = c(0, 10, 20, 30, 45, 65))
bigplot("angina", omit = T)
```

*No `angina` data for 2016 and 2017

### Asthma (in Younger Adults)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("asthma_young", cut = c(0, 10, 20, 30, 45, 125))
bigplot("asthma_young")
```

### Asthma/COPD (in Older Adults)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("asthma_older", cut = c(100, 250, 400, 600, 800, 1000))
bigplot("asthma_older")
```

### Pneumonia
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("pneumonia", cut = c(50, 100, 200, 300, 400, 550))
bigplot("pneumonia")
```

### Dehydration
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("dehydration", cut = c(30, 80, 100, 150, 200, 320))
bigplot("dehydration")
```

### Diabetes (Short-Term Complications)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("diabetes_st", cut = c(15, 45, 75, 100, 120, 150))
bigplot("diabetes_st")
```

### Diabetes (Long-Term Complications)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("diabetes_lt", cut = c(20, 50, 80, 100, 150, 230))
bigplot("diabetes_lt")
```

### Diabetes (Uncontrolled)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("diabetes_uc", cut = c(0, 5, 15, 30, 60, 100))
bigplot("diabetes_uc")
```

### Amputation (from Diabetes)
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("amputation_diab", cut = c(0, 10, 20, 30, 45, 65))
bigplot("amputation_diab")
```

### Heart Failure
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("heart_fail", cut = c(120, 200, 300, 400, 500, 600))
bigplot("heart_fail")
```

### Hypertension
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("hypertension", cut = c(0, 10, 25, 40, 60, 120))
bigplot("hypertension")
```

### Perforated Appendix
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("perf_appendix", cut = c(15, 35, 50, 100, 500, 700))
bigplot("perf_appendix")
```

*Why such a high increase in 2016-2017? Maybe data collection different?*

## UTI
```{r, fig.height = 9, fig.width = 14, echo = F}
bigplot("uti", cut = c(35, 100, 125, 150, 200, 270))
bigplot("uti")
```

#manipulating Ruthe's data for ST modeling_XL
```{r, eval = F}
library("SpatioTemporal")
library("sp")

#latitude and longitude
loc = cali@data[,c(5,6,ncol(cali@data)-1,ncol(cali@data))]
loc$NAME = as.character(loc$NAME)
names(loc)[1] = "county"
loc$NAMELSAD = as.character(loc$NAMELSAD)

#xy coordinates using WGS84
#source: https://rpubs.com/dasaptaerwin/19879
xy <- as.data.frame(loc[,c(3,4)])
xy <- as.data.frame(apply(xy,2,function(x){as.numeric(as.character(x))}))
cord.dec = SpatialPoints(cbind(xy$INTPTLON,-xy$INTPTLAT), 
                         proj4string=CRS("+proj=longlat"))
coord <- as.data.frame(spTransform(cord.dec, CRS("+init=epsg:32748")))

#combine latlong and coordinates
loc.all <- data.frame(loc,x = coord$coords.x1, y = coord$coords.x2)

#merge; county as a factor
datnew = left_join(dat,loc.all,by = "county") %>% 
  mutate(ID = factor(county)) %>%
  rename(lat = INTPTLAT, long = INTPTLON)

#outcome data for all categories
outcome_data <- datnew %>%  
  select(-age60_perc,-bachelor_perc,
         -est.white.percent,-est.black.percent,-pm25)

#Let's say we pick dehydration as an outcome
#dehydration only, wide format
#matrix
outcome_dehy <- outcome_data %>% select(ID,year, dehydration) %>%
  spread(key = ID,value = dehydration)

outcome_dehydration <- as.matrix(outcome_dehy[,-1],nrow = 8)
rownames(outcome_dehydration) = c(2010,2011,2012,2013,2014,2015,2016,2017)
colnames(outcome_dehydration) = unique(datnew$county)

#convarites (non-time-varying): I chose 2015 (this may change later)
#data.frame
covariate <- datnew %>% filter(year == 2015)  %>%
  select(ID,x,y,lat,long,age60_perc,bachelor_perc,
         est.white.percent,est.black.percent) %>%
  mutate(type = factor(rep(1,n())))

#check covaraite data is ok
#stCheckCovars(covariate, ID.unique = character(0)) #ok

#time-varying covariate: pm25
#matrix
stcov = datnew %>% select(year,ID,pm25) %>% spread(key = ID,value = pm25)
stcov <- as.matrix(stcov[,-1],nrow = 8)
rownames(stcov) = c(2010,2011,2012,2013,2014,2015,2016,2017)
colnames(stcov) = unique(datnew$county)

#list to create STdata object
st_dehy <- list(obs = outcome_dehydration, X = covariate,
               stcov = stcov)

#STdata Object!
st_dehy_obj <- createSTdata(st_dehy$obs, st_dehy$X, 
                            SpatioTemporal = list(st_pm2.5 = stcov))
# plot(st_dehy_obj,"loc")
# print(st_dehy_obj)

#try to create a STmodel: not working
LUR <- list(~est.black.percent + age60_perc + bachelor_perc)
ST <- "pm25"
locations <- list(coords = c("x","y"), long.lat = c("long", "lat"),others = "type")
cov.beta <- list(covf = "exp", nugget = FALSE)
cov.nu <- list(covf = "exp", nugget = ~type, random.effect = FALSE)
createSTmodel(st_dehy_obj, LUR = LUR, ST = ST, cov.beta = cov.beta, 
              cov.nu = cov.nu, locations = locations)


```

Limitation: lot of zeros for days above national $\text{PM}_{2.5}$ standard






